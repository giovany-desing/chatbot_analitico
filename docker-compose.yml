services:
  # ============ App (FastAPI) ============
  app:
    build: .
    container_name: chatbot_analitico_app
    ports:
      - "8000:8000"
    environment:
      # MySQL en AWS RDS (externo)
      - MYSQL_HOST=${MYSQL_HOST}
      - MYSQL_PORT=${MYSQL_PORT}
      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
      - MYSQL_DATABASE=${MYSQL_DATABASE}

      # Redis (local)
      - REDIS_URL=redis://redis:6379/0
      - REDIS_TTL=${REDIS_TTL}

      # PostgreSQL (local)
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}

      # LLM
      - GROQ_API_KEY=${GROQ_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LLM_MODEL=${LLM_MODEL}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS}
      - LLM_TIMEOUT=${LLM_TIMEOUT}

      # App
      - APP_NAME=${APP_NAME}
      - APP_VERSION=${APP_VERSION}
      - DEBUG=${DEBUG}
      - LOG_LEVEL=${LOG_LEVEL}

      # Fine-tuned Model
      - FINETUNED_MODEL_ENDPOINT=${FINETUNED_MODEL_ENDPOINT}
      - USAR_FINETUNED_MODEL=${USAR_FINETUNED_MODEL}

    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy

    volumes:
      - ./app:/app/app
      - ./data:/app/data
      - ./tests:/app/tests  # Volumen para tests
      - ./scripts:/app/scripts  # Volumen para scripts

    networks:
      - chatbot_network

    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health', timeout=5)"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

    # En macOS, Docker Desktop puede tener problemas accediendo a servicios externos
    # Si RDS no es accesible, verifica:
    # 1. RDS tiene "Publicly accessible" = Yes
    # 2. Security Group permite 0.0.0.0/0
    # 3. Network ACLs permiten tr√°fico

    restart: unless-stopped

  # ============ Frontend (Streamlit) ============
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    container_name: chatbot_frontend
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://app:8000
    depends_on:
      app:
        condition: service_healthy
    networks:
      - chatbot_network
    restart: unless-stopped

  # ============ Redis (Cache) ============
  redis:
    image: redis:7-alpine
    container_name: chatbot_redis
    ports:
      - "6379:6379"
    volumes:
        - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    networks:
      - chatbot_network
    restart: unless-stopped

  # ============ PostgreSQL + pgvector (RAG) ============
  postgres:
    image: ankane/pgvector:latest
    container_name: chatbot_postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init_postgres.sql:/docker-entrypoint-initdb.d/init.sql
      - ./migrations:/migrations  # Volumen para migraciones SQL
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U chatbot_user || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - chatbot_network
    restart: unless-stopped

  # ============ Cron Job para Exportaci√≥n de Datos de Entrenamiento ============
  cron-retraining:
    build: .
    container_name: chatbot_cron_retraining
    environment:
      # MySQL en AWS RDS (externo)
      - MYSQL_HOST=${MYSQL_HOST}
      - MYSQL_PORT=${MYSQL_PORT}
      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
      - MYSQL_DATABASE=${MYSQL_DATABASE}

      # Redis (local)
      - REDIS_URL=redis://redis:6379/0
      - REDIS_TTL=${REDIS_TTL}

      # PostgreSQL (local)
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}

      # LLM (necesario para el script)
      - GROQ_API_KEY=${GROQ_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LLM_MODEL=${LLM_MODEL}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS}
      - LLM_TIMEOUT=${LLM_TIMEOUT}

      # App
      - APP_NAME=${APP_NAME}
      - APP_VERSION=${APP_VERSION}
      - DEBUG=${DEBUG}
      - LOG_LEVEL=${LOG_LEVEL}

    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

    volumes:
      - ./app:/app/app
      - ./data:/app/data
      - ./scripts:/app/scripts

    networks:
      - chatbot_network

    # Ejecuta el script cada semana (604800 segundos = 7 d√≠as)
    # Espera 1 hora inicial para que los servicios est√©n listos
    command: >
      sh -c "
      echo '‚è∞ Cron job de exportaci√≥n de datos de entrenamiento iniciado';
      echo '   Esperando 1 hora para que los servicios est√©n listos...';
      sleep 3600;
      while true; do
        echo 'üìä Iniciando exportaci√≥n de datos de entrenamiento...';
        python scripts/auto_export_training_data.py --days 7 --min-confidence 0.8 --min-rating 4 --output-dir data/retraining || echo '‚ùå Error en exportaci√≥n';
        echo '‚úÖ Exportaci√≥n completada. Pr√≥xima ejecuci√≥n en 1 semana...';
        sleep 604800;
      done
      "

    restart: unless-stopped

volumes:
  redis_data:
  postgres_data:
  

networks:
  chatbot_network:
    driver: bridge
